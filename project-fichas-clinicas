# src/train_loop.py
from __future__ import annotations
"""
Entrenamiento supervisado con validaci√≥n y early stopping.

- Carga train/val desde data/processed (CSV)
- Crea el modelo v√≠a src.model.make_model(cfg)
- LOGREG: fit √∫nico + evaluaci√≥n en val
- MLP: entrenamiento incremental (warm_start) con early stopping (patience=10)
- Guarda:
    - results/model.joblib  (mejor checkpoint por AUROC_val)
    - results/train_log.csv (hist√≥rico por √©poca)
"""

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import joblib
import numpy as np
import pandas as pd
from sklearn.metrics import average_precision_score, roc_auc_score

from src.model import default_config, make_model


@dataclass
class TrainConfig:
    model_cfg: Dict[str, Any]
    max_epochs: int = 100
    patience: int = 10
    outdir: Path = Path("results")


def _load_xy(csv_path: Path, target: str = "label") -> Tuple[pd.DataFrame, pd.Series]:
    df = pd.read_csv(csv_path)
    if target not in df.columns:
        raise ValueError(f"No encuentro la columna objetivo '{target}' en {csv_path}")
    y = df[target].astype(int)
    X = df.drop(columns=[target])
    return X, y


def _class_weight_sample_weights(y: pd.Series) -> Optional[np.ndarray]:
    """Ponderaci√≥n por clase para pasar como sample_weight (√∫til en MLP)."""
    try:
        classes, counts = np.unique(y, return_counts=True)
        if len(classes) < 2:
            return None
        total = len(y)
        weights = {c: total / (len(classes) * cnt) for c, cnt in zip(classes, counts)}
        return np.array([weights[int(t)] for t in y.tolist()], dtype=float)
    except Exception:
        return None


def _eval_metrics(y_true: np.ndarray, proba: np.ndarray) -> Dict[str, float]:
    out: Dict[str, float] = {}
    try:
        out["auroc"] = roc_auc_score(y_true, proba)
    except Exception:
        out["auroc"] = float("nan")
    try:
        out["auprc"] = average_precision_score(y_true, proba)
    except Exception:
        out["auprc"] = float("nan")
    return out


def _save_log(log_rows: list[Dict[str, Any]], out_csv: Path) -> None:
    df = pd.DataFrame(log_rows)
    out_csv.parent.mkdir(parents=True, exist_ok=True
                         )
    df.to_csv(out_csv, index=False)


def _save_model(model, out_path: Path) -> None:
    out_path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(model, out_path)


def _is_mlp(model) -> bool:
    return model.__class__.__name__.lower().startswith("mlp")


def train_and_validate(cfg: TrainConfig, data_dir: Path, target: str = "label") -> None:
    # Carga datos
    Xtr, ytr = _load_xy(data_dir / "train.csv", target=target)
    Xva, yva = _load_xy(data_dir / "val.csv", target=target)

    # Modelo
    model = make_model(cfg.model_cfg)

    # Salidas
    outdir = cfg.outdir
    outdir.mkdir(parents=True, exist_ok=True)
    model_path = outdir / "model.joblib"
    log_path = outdir / "train_log.csv"

    log_rows: list[Dict[str, Any]] = []

    if not _is_mlp(model):
        # LOGREG (u otro estimador convencional)
        model.fit(Xtr, ytr)
        proba_va = model.predict_proba(Xva)[:, 1]
        metrics_va = _eval_metrics(yva.values, proba_va)
        log_rows.append({"epoch": 1, **metrics_va})
        _save_log(log_rows, log_path)
        _save_model(model, model_path)
        print(f"‚úî Modelo guardado en: {model_path}")
        print(f"Val AUROC={metrics_va['auroc']:.4f} AUPRC={metrics_va['auprc']:.4f}")
        return

    # MLP incremental + early stopping por AUROC
    params = model.get_params()
    if params.get("max_iter", 1) != 1:
        model.set_params(max_iter=1)
    if not params.get("warm_start", False):
        try:
            model.set_params(warm_start=True)
        except Exception:
            pass

    sw = _class_weight_sample_weights(ytr)

    best_auroc = -np.inf
    best_epoch = 0
    best_state: Optional[bytes] = None
    epochs_no_improve = 0

    for epoch in range(1, cfg.max_epochs + 1):
        try:
            model.fit(Xtr, ytr, sample_weight=sw)
        except TypeError:
            model.fit(Xtr, ytr)

        proba_va = model.predict_proba(Xva)[:, 1]
        metrics_va = _eval_metrics(yva.values, proba_va)
        log_rows.append({"epoch": epoch, **metrics_va})

        auroc = metrics_va["auroc"]
        if np.isfinite(auroc) and auroc > best_auroc:
            best_auroc = auroc
            best_epoch = epoch
            best_state = joblib.dumps(model)
            epochs_no_improve = 0
        else:
            epochs_no_improve += 1

        print(
            f"Epoch {epoch:03d} | Val AUROC={metrics_va['auroc']:.4f} "
            f"AUPRC={metrics_va['auprc']:.4f} | Best@{best_epoch}={best_auroc:.4f} "
            f"| no_improve={epochs_no_improve}/{cfg.patience}"
        )

        if epochs_no_improve >= cfg.patience:
            print("‚èπ Early stopping activado.")
            break

    _save_log(log_rows, log_path)
    if best_state is not None:
        best_model = joblib.loads(best_state)
        _save_model(best_model, model_path)
        print(f"‚úî Mejor modelo (epoch {best_epoch}) guardado en: {model_path}")
    else:
        _save_model(model, model_path)
        print("‚ö† No hubo mejora; guardado el modelo final.")

    print(f"üìÑ Log de entrenamiento: {log_path}")


def _load_json(path: Optional[str]) -> Dict[str, Any]:
    if not path:
        return {}
    p = Path(path)
    with open(p, "r", encoding="utf-8") as f:
        return json.load(f)


if __name__ == "__main__":
    import argparse

    ap = argparse.ArgumentParser(
        description="Entrenamiento con validaci√≥n y early stopping (MLP)."
    )
    ap.add_argument("--data-dir", default="data/processed")
    ap.add_argument("--config", default="")
    ap.add_argument("--model", default="mlp", choices=["mlp", "logreg"])
    ap.add_argument("--max-epochs", type=int, default=100)
    ap.add_argument("--patience", type=int, default=10)
    ap.add_argument("--outdir", default="results")
    args = ap.parse_args()

    cfg_json = _load_json(args.config)
    model_cfg = cfg_json if cfg_json else default_config(args.model)

    train_cfg = TrainConfig(
        model_cfg=model_cfg,
        max_epochs=int(args.max_epochs),
        patience=int(args.patience),
        outdir=Path(args.outdir),
    )
    train_and_validate(train_cfg, Path(args.data_dir))
