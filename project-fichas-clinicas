# src/api.py
from __future__ import annotations
"""
API de inferencia con FastAPI.

Endpoints:
- GET  /health        -> estado del servicio
- GET  /schema        -> columnas crudas esperadas por el preprocesador
- POST /predict       -> probabilidad y clase (umbral configurable)

Requisitos (artefactos entrenados):
- results/model.joblib
- results/preprocessor.joblib
"""

from pathlib import Path
from typing import Any, Dict, List, Optional
# src/evaluate.py
from __future__ import annotations
"""
Evaluaci√≥n en TEST:
- Carga results/model.joblib
- Lee data/processed/test.csv
- Calcula AUROC/AUPRC y m√©tricas a umbral
- Guarda ROC.png, PR.png y test_metrics.json
"""

from pathlib import Path
from typing import Dict, Tuple

import joblib
import numpy as np
import pandas as pd

from src.metrics import (
    compute_classification_metrics,
    confusion_counts,
    plot_pr,
    plot_roc,
    save_json,
)
# src/metrics.py
from __future__ import annotations
"""
M√©tricas y gr√°ficos para clasificaci√≥n binaria.

Funciones:
- compute_classification_metrics: AUROC, AUPRC y m√©tricas a umbral (acc/prec/recall/F1)
- confusion_counts: TP, FP, TN, FN
- plot_roc: guarda curva ROC
- plot_pr: guarda curva Precision-Recall
- save_json: escribe un dict en JSON
"""

from pathlib import Path
from typing import Dict, Tuple

import json
import numpy as np
import pandas as pd
from sklearn.metrics import (
    accuracy_score,
    average_precision_score,
    confusion_matrix,
    f1_score,
    precision_recall_curve,
    precision_score,
    recall_score,
    roc_auc_score,
    roc_curve,
)
import matplotlib.pyplot as plt


def compute_classification_metrics(
    y_true: np.ndarray,
    y_proba: np.ndarray,
    threshold: float = 0.5,
) -> Dict[str, float]:
    """Calcula AUROC, AUPRC y m√©tricas a un umbral dado."""
    out: Dict[str, float] = {}

    # Probabilidades bien formadas
    y_true = np.asarray(y_true).astype(int)
    y_proba = np.asarray(y_proba).astype(float)

    # M√©tricas umbraladas
    y_pred = (y_proba >= float(threshold)).astype(int)

    # M√©tricas robustas (maneja excepciones si solo hay una clase)
    try:
        out["auroc"] = roc_auc_score(y_true, y_proba)
    except Exception:
        out["auroc"] = float("nan")

    try:
        out["auprc"] = average_precision_score(y_true, y_proba)
    except Exception:
        out["auprc"] = float("nan")

    out["accuracy"] = accuracy_score(y_true, y_pred)
    out["precision"] = precision_score(y_true, y_pred, zero_division=0)
    out["recall"] = recall_score(y_true, y_pred, zero_division=0)
    out["f1"] = f1_score(y_true, y_pred, zero_division=0)

    return out


def confusion_counts(
    y_true: np.ndarray,
    y_pred: np.ndarray,
) -> Dict[str, int]:
    """Retorna TP, FP, TN, FN en un dict."""
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    return {"tp": int(tp), "fp": int(fp), "tn": int(tn), "fn": int(fn)}


def plot_roc(
    y_true: np.ndarray,
    y_proba: np.ndarray,
    out_path: Path,
) -> None:
    """Guarda curva ROC en out_path (PNG)."""
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    try:
        auc = roc_auc_score(y_true, y_proba)
    except Exception:
        auc = float("nan")

    plt.figure()
    plt.plot(fpr, tpr, label=f"ROC AUC = {auc:.3f}")
    plt.plot([0, 1], [0, 1], linestyle="--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(out_path, bbox_inches="tight", dpi=150)
    plt.close()


def plot_pr(
    y_true: np.ndarray,
    y_proba: np.ndarray,
    out_path: Path,
) -> None:
    """Guarda curva Precision-Recall en out_path (PNG)."""
    precision, recall, _ = precision_recall_curve(y_true, y_proba)
    try:
        auprc = average_precision_score(y_true, y_proba)
    except Exception:
        auprc = float("nan")

    plt.figure()
    plt.plot(recall, precision, label=f"AUPRC = {auprc:.3f}")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Precision-Recall Curve")
    plt.legend(loc="lower left")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(out_path, bbox_inches="tight", dpi=150)
    plt.close()


def save_json(data: Dict, out_path: Path) -> None:
    """Guarda un diccionario en JSON (con indentaci√≥n)."""
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def table_from_metrics(d: Dict[str, float]) -> pd.DataFrame:
    """Convierte el dict de m√©tricas a DataFrame de una fila (√∫til para logs)."""
    return pd.D
# src/train_loop.py
from __future__ import annotations
"""
Entrenamiento supervisado con validaci√≥n y early stopping.


- Carga train/val desde data/processed (CSV)
- Crea el modelo v√≠a src.model.make_model(cfg)
- LOGREG: fit √∫nico + evaluaci√≥n en val
- MLP: entrenamiento incremental (warm_start) con early stopping (patience=10)
- Guarda:
    - results/model.joblib  (mejor checkpoint por AUROC_val)
    - results/train_log.csv (hist√≥rico por √©poca)
"""

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import joblib
import numpy as np
import pandas as pd
from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel, Field

MODEL_PATH = Path("results/model.joblib")
PREPROC_PATH = Path("results/preprocessor.joblib")

app = FastAPI(title="Clinical ML Inference API", version="1.0.0")


class PredictRequest(BaseModel):
    features: Dict[str, Any] = Field(..., description="Mapa columna -> valor")


class PredictResponse(BaseModel):
    ok: bool
    proba: float
    label: int
    threshold: float
    missing: List[str] = []
    extra: List[str] = []


def _load_artifacts():
    if not MODEL_PATH.exists():
        raise FileNotFoundError(f"No se encontr√≥ el modelo en {MODEL_PATH}")
    if not PREPROC_PATH.exists():
        raise FileNotFoundError(f"No se encontr√≥ el preprocesador en {PREPROC_PATH}")
    model = joblib.load(MODEL_PATH)
    pre = joblib.load(PREPROC_PATH)
    return model, pre


def _infer_raw_columns_from_preprocessor(pre) -> Dict[str, List[str]]:
    numeric_cols: List[str] = []
    categorical_cols: List[str] = []
    for name, _trans, cols in pre.transformers_:
        if name == "remainder":
            continue
        if not isinstance(cols, list):
            try:
                if hasattr(pre, "feature_names_in_"):
                    cols = list(pre.feature_names_in_)
                else:
                    cols = []
            except Exception:
                cols = []
        if name == "num":
            numeric_cols.extend([str(c) for c in cols])
        elif name == "cat":
            categorical_cols.extend([str(c) for c in cols])
    return {"numeric": numeric_cols, "categorical": categorical_cols}


try:
    _MODEL, _PREPROC = _load_artifacts()
    _RAW_SCHEMA = _infer_raw_columns_from_preprocessor(_PREPROC)
    _ALIVE = True
except Exception as e:  # noqa: BLE001
    _MODEL, _PREPROC, _RAW_SCHEMA = None, None, {"numeric": [], "categorical": []}
    _ALIVE = False
    _STARTUP_ERROR = str(e)


@app.get("/health")
def health():
    return {
        "ok": _ALIVE,
        "model_path": str(MODEL_PATH),
        "preprocessor_path": str(PREPROC_PATH),
        "error": None if _ALIVE else _STARTUP_ERROR,
    }


@app.get("/schema")
def schema():
    if not _ALIVE:
        raise HTTPException(status_code=503, detail=_STARTUP_ERROR)
    return _RAW_SCHEMA


def _dataframe_from_features(
    features: Dict[str, Any],
    raw_schema: Dict[str, List[str]],
) -> pd.DataFrame:
    """
    Construye un DataFrame de UNA fila con las columnas crudas esperadas.
    Llena faltantes con None; deja extras para reportarlas.
    """
    cols = list(raw_schema["numeric"]) + list(raw_schema["categorical"])
    data: Dict[str, List[Any]] = {}
    for c in cols:
        data[c] = [features.get(c, None)]
    df = pd.DataFrame(data)
    return df


@app.post("/predict", response_model=PredictResponse)
def predict(
    req: PredictRequest,
    threshold: float = Query(0.5, ge=0.0, le=1.0, description="Umbral para clasificar"),
):
    if not _ALIVE:
        raise HTTPException(status_code=503, detail=_STARTUP_ERROR)

    # Construye DF crudo
    df_raw = _dataframe_from_features(req.features, _RAW_SCHEMA)

    # Detecta faltantes y extras (solo informativo)
    expected = set(_RAW_SCHEMA["numeric"] + _RAW_SCHEMA["categorical"])
    got = set(req.features.keys())
    missing = sorted(list(expected - got))
    extra = sorted(list(got - expected))

    # Transforma
    try:
        X = _PREPROC.transform(df_raw)
    except Exception as e:  # noqa: BLE001
        raise HTTPException(status_code=400, detail=f"Error en preprocesamiento: {e}")

    # Predice
    try:
        proba = float(_MODEL.predict_proba(X)[:, 1][0])
    except Exception as e:  # noqa: BLE001
        raise HTTPException(status_code=500, detail=f"Error en predicci√≥n: {e}")

    label = int(proba >= float(threshold))
    return PredictResponse(
        ok=True,
        proba=proba,
        label=label,
        threshold=float(threshold),
        missing=missing,
        extra=extra,
    )
from sklearn.metrics import average_precision_score, roc_auc_score

from src.model import default_config, make_model


@dataclass
class TrainConfig:
    model_cfg: Dict[str, Any]
    max_epochs: int = 100
    patience: int = 10
    outdir: Path = Path("results")


def _load_xy(csv_path: Path, target: str = "label") -> Tuple[pd.DataFrame, pd.Series]:
    df = pd.read_csv(csv_path)
    if target not in df.columns:
        raise ValueError(f"No encuentro la columna objetivo '{target}' en {csv_path}")
    y = df[target].astype(int)
    X = df.drop(columns=[target])
    return X, y


def evaluate_model(
    model_path: Path,
    test_csv: Path,
    outdir: Path,
    threshold: float = 0.5,
) -> Dict:
    """Eval√∫a el modelo en test y guarda artefactos."""
    outdir.mkdir(parents=True, exist_ok=True)

    # Carga modelo y datos
    model = joblib.load(model_path)
    Xte, yte = _load_xy(test_csv, target="label")

    # Predicciones
    proba = model.predict_proba(Xte)[:, 1]
    y_pred = (proba >= threshold).astype(int)

    # M√©tricas
    metrics = compute_classification_metrics(yte.values, proba, threshold=threshold)
    conf = confusion_counts(yte.values, y_pred)

    # Gr√°ficos
    plot_roc(yte.values, proba, outdir / "roc_curve.png")
    plot_pr(yte.values, proba, outdir / "pr_curve.png")

    # Guarda JSON
    out = {
        "threshold": float(threshold),
        "metrics": metrics,
        "confusion": conf,
        "n_test": int(len(yte)),
    }
    save_json(out, outdir / "test_metrics.json")
    return out
def _class_weight_sample_weights(y: pd.Series) -> Optional[np.ndarray]:
    """
    Calcula weights por clase para pasar como sample_weight a estimadores
    que no soportan class_weight directamente (como MLPClassifier).
    Devuelve None si hay problema.
    """
    try:
        classes, counts = np.unique(y, return_counts=True)
        freq = dict(zip(classes.tolist(), counts.tolist()))
        if len(freq) < 2:
            return None  # no se puede ponderar una sola clase
        total = len(y)
        # weight_c = total / (num_clases * count_c)
        weights = {c: total / (len(freq) * cnt) for c, cnt in freq.items()}
        return np.array([weights[int(t)] for t in y.tolist()], dtype=float)
    except Exception:
        return None


def _eval_metrics(y_true: np.ndarray, proba: np.ndarray) -> Dict[str, float]:
    """
    Calcula AUROC y AUPRC. Maneja casos edge cuando no hay ambas clases.
    """
    out: Dict[str, float] = {}
    try:
        out["auroc"] = roc_auc_score(y_true, proba)
    except Exception:
        out["auroc"] = float("nan")
    try:
        out["auprc"] = average_precision_score(y_true, proba)
    except Exception:
        out["auprc"] = float("nan")
    return out


def _save_log(log_rows: list[Dict[str, Any]], out_csv: Path) -> None:
    df = pd.DataFrame(log_rows)
    out_csv.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(out_csv, index=False)


def _save_model(model, out_path: Path) -> None:
    out_path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(model, out_path)


def _is_mlp(model) -> bool:
    return model.__class__.__name__.lower().startswith("mlp")


def train_and_validate(cfg: TrainConfig, data_dir: Path, target: str = "label") -> None:
    # --- carga datos ---
    Xtr, ytr = _load_xy(data_dir / "train.csv", target=target)
    Xva, yva = _load_xy(data_dir / "val.csv", target=target)

    # --- construye modelo ---
    model = make_model(cfg.model_cfg)

    # --- rutas de salida ---
    outdir = cfg.outdir
    outdir.mkdir(parents=True, exist_ok=True)
    model_path = outdir / "model.joblib"
    log_path = outdir / "train_log.csv"

    log_rows: list[Dict[str, Any]] = []

    if not _is_mlp(model):
        # ----- LOGREG (u otro estimador no incremental): fit √∫nico -----
        model.fit(Xtr, ytr)
        proba_va = model.predict_proba(Xva)[:, 1]
        metrics_va = _eval_metrics(yva.values, proba_va)
        log_rows.append({"epoch": 1, **metrics_va})
        _save_log(log_rows, log_path)
        _save_model(model, model_path)
        print(f"‚úî Modelo guardado en: {model_path}")
        print(f"Val AUROC={metrics_va['auroc']:.4f} AUPRC={metrics_va['auprc']:.4f}")
        return

    # ----- MLP con early stopping manual e incremental -----
    # Configuramos para entrenamiento por √©pocas controladas:
    # - max_iter=1 y warm_start=True para avanzar 1 "√©poca" por fit()
    # - usamos sample_weight para class balance
    params = model.get_params()
    if params.get("max_iter", 1) != 1:
        model.set_params(max_iter=1)
    if not params.get("warm_start", False):
        try:
            model.set_params(warm_start=True)
        except Exception:
            pass  # algunos estimadores podr√≠an no soportar warm_start

    # Ponderaci√≥n por clase
    sw = _class_weight_sample_weights(ytr)

    best_auroc = -np.inf
    best_epoch = 0
    best_state: Optional[bytes] = None
    epochs_no_improve = 0

    for epoch in range(1, cfg.max_epochs + 1):
        # Una "√©poca" de actualizaci√≥n
        try:
            model.fit(Xtr, ytr, sample_weight=sw)  # para MLPClassifier es v√°lido
        except TypeError:
            # fallback si no acepta sample_weight
            model.fit(Xtr, ytr)

        # Eval en validaci√≥n
        proba_va = model.predict_proba(Xva)[:, 1]
        metrics_va = _eval_metrics(yva.values, proba_va)
        log_rows.append({"epoch": epoch, **metrics_va})

        # Early stopping por AUROC
        auroc = metrics_va["auroc"]
        if np.isfinite(auroc) and auroc > best_auroc:
            best_auroc = auroc
            best_epoch = epoch
            # guardamos snapshot binario del modelo (pickle) en memoria
            best_state = joblib.dumps(model)
            epochs_no_improve = 0
        else:
            epochs_no_improve += 1

        print(
            f"Epoch {epoch:03d} | Val AUROC={metrics_va['auroc']:.4f} "
            f"AUPRC={metrics_va['auprc']:.4f} | "
            f"Best@{best_epoch}={best_auroc:.4f} | "
            f"no_improve={epochs_no_improve}/{cfg.patience}"
        )

        if epochs_no_improve >= cfg.patience:
            print("‚èπ Early stopping activado.")
            break

    # Guardar log y mejor checkpoint
    _save_log(log_rows, log_path)
    if best_state is not None:
        best_model = joblib.loads(best_state)
        _save_model(best_model, model_path)
        print(f"‚úî Mejor modelo (epoch {best_epoch}) guardado en: {model_path}")
    else:
        # si nunca mejor√≥, guardamos el modelo actual
        _save_model(model, model_path)
        print("‚ö† No hubo mejora; guardado el modelo final.")

    print(f"üìÑ Log de entrenamiento: {log_path}")


def _load_json(path: Optional[str]) -> Dict[str, Any]:
    if not path:
        return {}
    p = Path(path)
    with open(p, "r", encoding="utf-8") as f:
        return json.load(f)
# src/model.py
from __future__ import annotations
"""
Definici√≥n de modelos:
- Regresi√≥n Log√≠stica (baseline)
- MLPClassifier (red densa con backprop)
Uso:
    from src.model import make_model, default_config
    cfg = default_config(model="mlp")  # o "logreg"
    model = make_model(cfg)
    model.fit(X_train, y_train)
    y_proba = model.predict_proba(X_val)[:, 1]
"""

from typing import Any, Dict

from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier


def default_config(model: str = "mlp") -> Dict[str, Any]:
    """
    Config por defecto para cada modelo.
    - model: "logreg" | "mlp"
    """
    if model == "logreg":
        return {
            "model": "logreg",
            "logreg": {
                "max_iter": 200,
                "class_weight": "balanced",
                "solver": "lbfgs",
                "n_jobs": None,  # usa todos si None y solver lo permite
                "random_state": 42,
            },
        }
    if model == "mlp":
        return {
            "model": "mlp",
            "mlp": {
                "hidden_layer_sizes": [128, 64],
                "activation": "relu",
                "solver": "adam",
                "alpha": 1e-4,               # L2
                "batch_size": "auto",
                "learning_rate": "adaptive",  # adapta LR si se estanca
                "learning_rate_init": 1e-3,
                "max_iter": 100,
                "early_stopping": True,
                "n_iter_no_change": 10,       # paciencia (val)
                "validation_fraction": 0.1,   # solo lo usa internamente el MLP
                "shuffle": True,
                "random_state": 42,
                "verbose": False,
            },
        }
    raise ValueError("Modelo no soportado. Usa 'logreg' o 'mlp'.")


def make_model(cfg: Dict[str, Any]):
    """
    Crea el estimador sklearn seg√∫n cfg.
    cfg ejemplo:
    {
        "model": "mlp",
        "mlp": {
            "hidden_layer_sizes": [128, 64],
            "max_iter": 100,
            "early_stopping": True,
            ...
        }
    }
    """
    model_name = cfg.get("model", "mlp").lower()

    if model_name == "logreg":
        p = (cfg.get("logreg") or {}).copy()
        # Defaults seguros si faltan
        p.setdefault("max_iter", 200)
        p.setdefault("class_weight", "balanced")
        p.setdefault("solver", "lbfgs")
        p.setdefault("n_jobs", None)
        p.setdefault("random_state", 42)
        return LogisticRegression(**p)

    if model_name == "mlp":
        p = (cfg.get("mlp") or {}).copy()
        # Defaults seguros si faltan
        p.setdefault("hidden_layer_sizes", [128, 64])
        p.setdefault("activation", "relu")
        p.setdefault("solver", "adam")
        p.setdefault("alpha", 1e-4)
        p.setdefault("batch_size", "auto")
        p.setdefault("learning_rate", "adaptive")
        p.setdefault("learning_rate_init", 1e-3)
        p.setdefault("max_iter", 100)
        p.setdefault("early_stopping", True)
        p.setdefault("n_iter_no_change", 10)
        p.setdefault("validation_fraction", 0.1)
        p.setdefault("shuffle", True)
        p.setdefault("random_state", 42)
        p.setdefault("verbose", False)

        # Acepta listas para hidden_layer_sizes
        if isinstance(p.get("hidden_layer_sizes"), list):
            p["hidden_layer_sizes"] = tuple(p["hidden_layer_sizes"])

        return MLPClassifier(**p)

    raise ValueError("Modelo no soportado. Usa 'logreg' o 'mlp'.")


def get_supported_models() -> Dict[str, str]:
    """Devuelve un mapa simple de modelos soportados."""
    return {
        "logreg": "LogisticRegression (baseline, lineal)",
        "mlp": "MLPClassifier (red densa con backprop, no lineal)",
    }
# src/preprocess.py
from __future__ import annotations
"""
Preprocesamiento tabular:
- Split estratificado en train/val/test
- Imputaci√≥n (num: mediana, cat: "unknown")
- Escalado num√©rico (z-score)
- One-hot en categ√≥ricas (handle_unknown="ignore")
- Guardado/carga del preprocesador con joblib
"""

from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple

import joblib
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler


@dataclass
class SplitData:
    X_train: pd.DataFrame
    y_train: pd.Series
    X_val: pd.DataFrame
    y_val: pd.Series
    X_test: pd.DataFrame
    y_test: pd.Series


def stratified_split(
    df: pd.DataFrame,
    target: str,
    val_size: float = 0.15,
    test_size: float = 0.15,
    random_state: int = 42,
) -> SplitData:
    """Hace split estratificado en train/val/test manteniendo proporciones."""
    y = df[target]
    X = df.drop(columns=[target])

    X_train, X_tmp, y_train, y_tmp = train_test_split(
        X,
        y,
        test_size=val_size + test_size,
        stratify=y,
        random_state=random_state,
    )
    rel_test = test_size / (val_size + test_size)
    X_val, X_test, y_val, y_test = train_test_split(
        X_tmp,
        y_tmp,
        test_size=rel_test,
        stratify=y_tmp,
        random_state=random_state,
    )
    return SplitData(X_train, y_train, X_val, y_val, X_test, y_test)


def infer_columns(
    df: pd.DataFrame,
    target: str,
    numeric_hint: List[str] | None = None,
    categorical_hint: List[str] | None = None,
) -> Tuple[List[str], List[str]]:
    """
    Infiera columnas num√©ricas y categ√≥ricas.
    Puedes forzar con *_hint*. El target se excluye siempre.
    """
    cols = [c for c in df.columns if c != target]
    if numeric_hint is not None or categorical_hint is not None:
        num = [c for c in (numeric_hint or []) if c in cols]
        cat = [c for c in (categorical_hint or []) if c in cols]
        rest = [c for c in cols if c not in num and c not in cat]
        # resto: asume categ√≥rico
        cat.extend(rest)
        return num, cat

    # inferencia simple por dtype
    num = [c for c in cols if pd.api.types.is_numeric_dtype(df[c])]
    cat = [c for c in cols if c not in num]
    return num, cat


def make_preprocessor(
    numeric_cols: List[str],
    categorical_cols: List[str],
) -> ColumnTransformer:
    """Crea el ColumnTransformer con imputaci√≥n + escalado/one-hot."""
    num_pipe = make_numeric_pipeline()
    cat_pipe = make_categorical_pipeline()
    pre = ColumnTransformer(
        transformers=[
            ("num", num_pipe, numeric_cols),
            ("cat", cat_pipe, categorical_cols),
        ]
    )
    return pre


def make_numeric_pipeline():
    """Imputaci√≥n mediana + escalado est√°ndar."""
    from sklearn.pipeline import Pipeline
    return Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler()),
        ]
    )


def make_categorical_pipeline():
    """Imputaci√≥n 'unknown' + one-hot (ignora categor√≠as nuevas)."""
    from sklearn.pipeline import Pipeline
    return Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="constant", fill_value="unknown")),
            ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False)),
        ]
    )


def fit_transform_all(
    split: SplitData,
    numeric_cols: List[str],
    categorical_cols: List[str],
    preprocessor_path: str | Path = "results/preprocessor.joblib",
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    Ajusta el preprocesador en train y transforma train/val/test.
    Guarda el preprocesador en disco para inferencia posterior.
    """
    pre = make_preprocessor(numeric_cols, categorical_cols)

    Xtr = pre.fit_transform(split.X_train)
    Xva = pre.transform(split.X_val)
    Xte = pre.transform(split.X_test)

    # nombres de columnas resultantes
    ohe = pre.named_transformers_["cat"]["ohe"]  # type: ignore[index]
    cat_names = list(ohe.get_feature_names_out(categorical_cols))
    num_names = numeric_cols
    out_cols = num_names + cat_names

    Xtr = pd.DataFrame(Xtr, columns=out_cols, index=split.X_train.index)
    Xva = pd.DataFrame(Xva, columns=out_cols, index=split.X_val.index)
    Xte = pd.DataFrame(Xte, columns=out_cols, index=split.X_test.index)

    Path(preprocessor_path).parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(pre, preprocessor_path)

    return Xtr, Xva, Xte


def load_preprocessor(preprocessor_path: str | Path):
    """Carga el preprocesador guardado en disco."""
    return joblib.load(preprocessor_path)


def transform_with_loaded(
    preprocessor,
    X: pd.DataFrame,
    numeric_cols: List[str],
    categorical_cols: List[str],
) -> pd.DataFrame:
    """Transforma un DataFrame con un preprocesador ya cargado."""
    Xt = preprocessor.transform(X)
    ohe = preprocessor.named_transformers_["cat"]["ohe"]  # type: ignore[index]
    cat_names = list(ohe.get_feature_names_out(categorical_cols))
    out_cols = list(numeric_cols) + cat_names
    return pd.DataFrame(Xt, columns=out_cols, index=X.index)



if __name__ == "__main__":
    import argparse
    import json

    ap = argparse.ArgumentParser(description="Evaluaci√≥n en test.")
    ap.add_argument(
        "--model",
        default="results/model.joblib",
        help="Ruta al modelo entrenado (joblib).",
    )
    ap.add_argument(
        "--test-csv",
        default="data/processed/test.csv",
        help="CSV de test (features + label).",

    ap = argparse.ArgumentParser(
        description="Entrenamiento con validaci√≥n y early stopping (MLP)."
    )
    ap.add_argument(
        "--data-dir",
        default="data/processed",
        help="Carpeta con train.csv y val.csv (por defecto data/processed).",
    )
    ap.add_argument(
        "--config",
        default="",
        help="Ruta a JSON con configuraci√≥n del modelo (opcional).",
    )
    ap.add_argument(
        "--model",
        default="mlp",
        choices=["mlp", "logreg"],
        help="Modelo por defecto si no se provee config JSON.",
    )
    ap.add_argument(
        "--max-epochs",
        type=int,
        default=100,
        help="M√°ximo de √©pocas para MLP (default=100).",
    )
    ap.add_argument(
        "--patience",
        type=int,
        default=10,
        help="Paciencia para early stopping por AUROC (default=10).",
    )
    ap.add_argument(
        "--outdir",
        default="results",
        help="Carpeta de salida (gr√°ficos y JSON).",
    )
    ap.add_argument(
        "--threshold",
        type=float,
        default=0.5,
        help="Umbral para m√©tricas a clase (default=0.5).",
    )
    args = ap.parse_args()

    summary = evaluate_model(
        model_path=Path(args.model),
        test_csv=Path(args.test_csv),
        outdir=Path(args.outdir),
        threshold=float(args.threshold),
    )
    print(json.dumps(summary, indent=2))
        help="Carpeta de salida para modelo y logs (default=results).",
    )
    args = ap.parse_args()

    # carga cfg
    cfg_json = _load_json(args.config)
    if cfg_json:
        model_cfg = cfg_json
    else:
        model_cfg = default_config(args.model)

    train_cfg = TrainConfig(
        model_cfg=model_cfg,
        max_epochs=int(args.max_epochs),
        patience=int(args.patience),
        outdir=Path(args.outdir),
    )

    train_and_validate(train_cfg, Path(args.data_dir))
        description="Preprocesa CSV tabular (split + transform) y guarda artefactos.",
    )
    ap.add_argument("--csv", required=True, help="Ruta al CSV de entrada.")
    ap.add_argument("--target", default="label", help="Nombre de la columna objetivo.")
    ap.add_argument(
        "--outdir",
        default="data/processed",
        help="Carpeta de salida para CSVs y preprocesador.",
    )
    args = ap.parse_args()

    df_in = pd.read_csv(args.csv)
    num_cols, cat_cols = infer_columns(df_in, target=args.target)

    split = stratified_split(df_in, target=args.target)
    Xtr, Xva, Xte = fit_transform_all(
        split, num_cols, cat_cols, preprocessor_path=Path(args.outdir) / "preprocessor.joblib"
    )

    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    pd.concat([Xtr, split.y_train], axis=1).to_csv(outdir / "train.csv", index=False)
    pd.concat([Xva, split.y_val], axis=1).to_csv(outdir / "val.csv", index=False)
    pd.concat([Xte, split.y_test], axis=1).to_csv(outdir / "test.csv", index=False)

    print("‚úî Guardado preprocesador en:", outdir / "preprocessor.joblib")
    print("‚úî train/val/test en:", outdir)
